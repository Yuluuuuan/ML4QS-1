{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chapter2.CreateDataset import CreateDataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "from util.VisualizeDataset import VisualizeDataset\n",
    "from util import util\n",
    "import time\n",
    "start = time.time()\n",
    "plt.rcParams[\"figure.figsize\"] = [15,5]\n",
    "\n",
    "from Chapter7.PrepareDatasetForLearning import PrepareDatasetForLearning\n",
    "from Chapter7.LearningAlgorithms import ClassificationAlgorithms\n",
    "from Chapter7.Evaluation import ClassificationEvaluation\n",
    "from Chapter7.FeatureSelection import FeatureSelectionClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/merged_data_Peter/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acceleration x (m/s^2)', 'Acceleration y (m/s^2)', 'Acceleration z (m/s^2)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accraw = pd.read_csv(data_path + \"Accelerometer.csv\")\n",
    "timecol = \"Time (s)\"\n",
    "accfeatures = list()\n",
    "for col in accraw:\n",
    "    if (col != timecol) and \\\n",
    "    (col != \"Absolute acceleration (m/s^2)\") and \\\n",
    "    (col != \"Unnamed: 0\") and \\\n",
    "    (col != \"Unnamed: 1\"):\n",
    "        accfeatures.append(col)\n",
    "accfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gyroscope x (rad/s)', 'Gyroscope y (rad/s)', 'Gyroscope z (rad/s)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gyraw = pd.read_csv(data_path + \"Gyroscope.csv\")\n",
    "gyfeatures = list()\n",
    "for col in gyraw:\n",
    "    if (col != timecol) and \\\n",
    "    (col != \"Absolute (rad/s)\") and \\\n",
    "    (col != \"Unnamed: 0\") and \\\n",
    "    (col != \"Unnamed: 1\"):\n",
    "        gyfeatures.append(col)\n",
    "gyfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from Accelerometer.csv\n"
     ]
    }
   ],
   "source": [
    "Dataset = CreateDataset(data_path , 500)\n",
    "\n",
    "Dataset.add_numerical_dataset(\"Accelerometer.csv\", timecol, accfeatures, \"avg\", \"acc_\")\n",
    "Dataset.add_numerical_dataset(\"Gyroscope.csv\", timecol, gyfeatures, \"avg\", \"gyr_\")\n",
    "Dataset.add_event_dataset('labels.csv', 'label_start', 'label_end', 'label', 'binary')\n",
    "\n",
    "dataset = Dataset.data_table\n",
    "Dataviz = VisualizeDataset()\n",
    "\n",
    "Dataviz.plot_dataset_boxplot(dataset, ['acc_Acceleration x (m/s^2)', 'acc_Acceleration y (m/s^2)', 'acc_Acceleration z (m/s^2)'])\n",
    "Dataviz.plot_dataset_boxplot(dataset, ['gyr_Gyroscope x (rad/s)', 'gyr_Gyroscope y (rad/s)', 'gyr_Gyroscope z (rad/s)'])\n",
    "\n",
    "Dataviz.plot_dataset(dataset, [\"acc_\", \"gyr_\", \"label\"], \\\n",
    "                        [\"like\", \"like\", \"like\"], \\\n",
    "                        [\"line\", \"line\", \"points\"])\n",
    "\n",
    "util.print_statistics(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FORWARD_SELECTION = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz = VisualizeDataset()\n",
    "prepare = PrepareDatasetForLearning()\n",
    "\n",
    "train_X, test_X, train_y, test_y = prepare.split_single_dataset_classification(dataset, ['label'], 'like', 0.7, filter=True, temporal=False)\n",
    "\n",
    "print('Training set length is: ', len(train_X.index))\n",
    "print('Test set length is: ', len(test_X.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_features = ['acc_Acceleration x (m/s^2)', 'acc_Acceleration y (m/s^2)', 'acc_Acceleration z (m/s^2)', 'gyr_Gyroscope x (rad/s)', 'gyr_Gyroscope y (rad/s)', 'gyr_Gyroscope z (rad/s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelectionClassification()\n",
    "features, ordered_features, ordered_scores = fs.forward_selection(N_FORWARD_SELECTION, \n",
    "                                                                  train_X[basic_features], \n",
    "                                                                  test_X[basic_features],\n",
    "                                                                  train_y,\n",
    "                                                                  test_y,\n",
    "                                                                  gridsearch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_xy(x=[range(1, N_FORWARD_SELECTION+1)], y=[ordered_scores],\n",
    "                xlabel='number of features', ylabel='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ClassificationAlgorithms()\n",
    "eval = ClassificationEvaluation()\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "reg_parameters = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "performance_training = []\n",
    "performance_test = []\n",
    "## Due to runtime constraints we run the experiment 3 times, yet if you want even more robust data one should increase the repetitions. \n",
    "N_REPEATS_NN = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg_param in reg_parameters:\n",
    "    performance_tr = 0\n",
    "    performance_te = 0\n",
    "    for i in range(0, N_REPEATS_NN):\n",
    "\n",
    "        class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.feedforward_neural_network(\n",
    "            train_X, train_y,\n",
    "            test_X, hidden_layer_sizes=(250, ), alpha=reg_param, max_iter=500,\n",
    "            gridsearch=False\n",
    "        )\n",
    "\n",
    "        performance_tr += eval.accuracy(train_y, class_train_y)\n",
    "        performance_te += eval.accuracy(test_y, class_test_y)\n",
    "    performance_training.append(performance_tr/N_REPEATS_NN)\n",
    "    performance_test.append(performance_te/N_REPEATS_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_xy(x=[reg_parameters, reg_parameters], y=[performance_training, performance_test], method='semilogx',\n",
    "                xlabel='regularization parameter value', ylabel='accuracy', ylim=[0.95, 1.01],\n",
    "                names=['training', 'test'], line_styles=['r-', 'b:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_KCV_REPEATS = 5\n",
    "\n",
    "print('Preprocessing took', time.time()-start, 'seconds.')\n",
    "\n",
    "scores_over_all_algs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train_X = train_X[basic_features]\n",
    "selected_test_X = test_X[basic_features]\n",
    "\n",
    "# First we run our non deterministic classifiers a number of times to average their score.\n",
    "\n",
    "performance_tr_nn = 0\n",
    "performance_tr_rf = 0\n",
    "performance_tr_svm = 0\n",
    "performance_te_nn = 0\n",
    "performance_te_rf = 0\n",
    "performance_te_svm = 0\n",
    "\n",
    "for repeat in range(0, N_KCV_REPEATS):\n",
    "    print(\"Training NeuralNetwork run {} / {} ... \".format(repeat, N_KCV_REPEATS))\n",
    "    class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.feedforward_neural_network(\n",
    "        selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    print(\"Training RandomForest run {} / {} ... \".format(repeat, N_KCV_REPEATS))\n",
    "    performance_tr_nn += eval.accuracy(train_y, class_train_y)\n",
    "    performance_te_nn += eval.accuracy(test_y, class_test_y)\n",
    "\n",
    "    class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.random_forest(\n",
    "        selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "    )\n",
    "\n",
    "    performance_tr_rf += eval.accuracy(train_y, class_train_y)\n",
    "    performance_te_rf += eval.accuracy(test_y, class_test_y)\n",
    "\n",
    "    print(\"Training SVM run {} / {}\".format(repeat, N_KCV_REPEATS))\n",
    "\n",
    "    class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.support_vector_machine_with_kernel(\n",
    "        selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    "    )\n",
    "    performance_tr_svm += eval.accuracy(train_y, class_train_y)\n",
    "    performance_te_svm += eval.accuracy(test_y, class_test_y)\n",
    "\n",
    "\n",
    "overall_performance_tr_nn = performance_tr_nn/N_KCV_REPEATS\n",
    "overall_performance_te_nn = performance_te_nn/N_KCV_REPEATS\n",
    "overall_performance_tr_rf = performance_tr_rf/N_KCV_REPEATS\n",
    "overall_performance_te_rf = performance_te_rf/N_KCV_REPEATS\n",
    "overall_performance_tr_svm = performance_tr_svm/N_KCV_REPEATS\n",
    "overall_performance_te_svm = performance_te_svm/N_KCV_REPEATS\n",
    "\n",
    "#     #And we run our deterministic classifiers:\n",
    "print(\"Determenistic Classifiers:\")\n",
    "\n",
    "print(\"Training Nearest Neighbor run 1 / 1\")\n",
    "class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.k_nearest_neighbor(\n",
    "    selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    ")\n",
    "performance_tr_knn = eval.accuracy(train_y, class_train_y)\n",
    "performance_te_knn = eval.accuracy(test_y, class_test_y)\n",
    "print(\"Training Descision Tree run 1 / 1\")\n",
    "class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.decision_tree(\n",
    "    selected_train_X, train_y, selected_test_X, gridsearch=True\n",
    ")\n",
    "\n",
    "performance_tr_dt = eval.accuracy(train_y, class_train_y)\n",
    "performance_te_dt = eval.accuracy(test_y, class_test_y)\n",
    "print(\"Training Naive Bayes run 1/1\")\n",
    "class_train_y, class_test_y, class_train_prob_y, class_test_prob_y = learner.naive_bayes(\n",
    "    selected_train_X, train_y, selected_test_X\n",
    ")\n",
    "\n",
    "performance_tr_nb = eval.accuracy(train_y, class_train_y)\n",
    "performance_te_nb = eval.accuracy(test_y, class_test_y)\n",
    "\n",
    "scores_with_sd = util.print_table_row_performances(len(selected_train_X.index), len(selected_test_X.index), [\n",
    "                                                                                            (overall_performance_tr_nn, overall_performance_te_nn),\n",
    "                                                                                            (overall_performance_tr_rf, overall_performance_te_rf),\n",
    "                                                                                            (overall_performance_tr_svm, overall_performance_te_svm),\n",
    "                                                                                            (performance_tr_knn, performance_te_knn),\n",
    "                                                                                            (performance_tr_knn, performance_te_knn),\n",
    "                                                                                            (performance_tr_dt, performance_te_dt),\n",
    "                                                                                            (performance_tr_nb, performance_te_nb)])\n",
    "scores_over_all_algs.append(scores_with_sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_with_sd = util.print_table_row_performances(\"Normal\", len(selected_train_X.index), len(selected_test_X.index), [\n",
    "                                                                                            (overall_performance_tr_nn, overall_performance_te_nn),\n",
    "                                                                                            (overall_performance_tr_rf, overall_performance_te_rf),\n",
    "                                                                                            (overall_performance_tr_svm, overall_performance_te_svm),\n",
    "                                                                                            (performance_tr_knn, performance_te_knn),\n",
    "                                                                                            (performance_tr_knn, performance_te_knn),\n",
    "                                                                                            (performance_tr_dt, performance_te_dt),\n",
    "                                                                                            (performance_tr_nb, performance_te_nb)])\n",
    "scores_over_all_algs.append(scores_with_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_performances_classification(['NN', 'RF','SVM', 'KNN', 'DT', 'NB'], \"Normal\", scores_over_all_algs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm = eval.confusion_matrix(test_y, class_test_y, class_train_prob_y.columns)\n",
    "\n",
    "DataViz.plot_confusion_matrix(test_cm, class_train_prob_y.columns, normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
